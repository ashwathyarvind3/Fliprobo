{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data. This task will be done in following steps: \n",
    "\n",
    "1. first get the webpage https://www.naukri.com/ \n",
    "2. Enter “Data Analyst” in “Skill,Designations,Companies” field and enter “Bangalore” in “enter the location” field. \n",
    "3. Then click the search button. \n",
    "4. Then scrape the data for the first 10 jobs results you get. \n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all the required libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(executable_path=\"C:\\\\Users\\\\HP\\\\Downloads\\\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.naukri.com/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_field_designation=driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "search_field_location=driver.find_element_by_id(\"qsb-location-sugg\")\n",
    "search_field_designation.send_keys(\"Data Analyst\")\n",
    "search_field_location.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists for scraping data\n",
    "Job_Title=[]\n",
    "Job_Location=[]\n",
    "Company_Name=[]\n",
    "Experience_Required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist/Data Analyst-immediate',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'ID&A - Data Analyst - Informatica MDM',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst - O2C - Bangalore',\n",
       " 'Business Data Analyst - Database Design/Mining',\n",
       " 'Data Analyst - MySQL/PostgreSQL',\n",
       " 'Hiring For Data Analyst On Contractual Role',\n",
       " 'Data Analyst (Telcom domain)',\n",
       " 'Data Analyst',\n",
       " 'Hiring For Data Analyst (On Contractual Role)',\n",
       " 'SENIOR DATA ANALYST',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst / Scientist',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'IDQ - Informatica Data quality + SQL - Data Analyst']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping the job-titles\n",
    "title=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "\n",
    "for i in title:\n",
    "    titles=i.text\n",
    "    Job_Title.append(titles)\n",
    "Job_Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chennai, Pune, Bengaluru, Hyderabad',\n",
       " 'Bengaluru',\n",
       " 'Mumbai, Bengaluru, Hyderabad',\n",
       " 'Bengaluru',\n",
       " 'Bengaluru',\n",
       " 'Bengaluru, Kolkata',\n",
       " 'Bengaluru',\n",
       " 'Bengaluru',\n",
       " 'Bengaluru',\n",
       " 'Pune, Mumbai, Bengaluru, Hyderabad, Noida, Jaipur',\n",
       " 'Bengaluru',\n",
       " 'Bengaluru',\n",
       " 'Bengaluru',\n",
       " 'Bengaluru',\n",
       " 'Bengaluru',\n",
       " 'Bengaluru',\n",
       " 'Bengaluru',\n",
       " 'Bengaluru',\n",
       " 'Bengaluru(2nd Phase JP Nagar)',\n",
       " 'Bengaluru / Bangalore']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping the job-location\n",
    "loc=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span\")\n",
    "\n",
    "for i in loc:\n",
    "    loca=i.text\n",
    "    Job_Location.append(loca)\n",
    "Job_Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CAIA-Center For Artificial Intelligence & Advanced Analytics',\n",
       " 'Applied Materials',\n",
       " 'Cognizant Technology Solutions India Pvt Ltd',\n",
       " 'Shell India Markets Private Limited',\n",
       " 'GlaxoSmithKline Pharmaceuticals Limited',\n",
       " 'Cognizant Technology Solutions India Pvt Ltd',\n",
       " 'Shell India Markets Private Limited',\n",
       " 'RANDSTAD INDIA PVT LTD',\n",
       " 'AugmatrixGo',\n",
       " 'Astegic',\n",
       " 'Flipkart Internet Private Limited',\n",
       " 'Oracle India Pvt. Ltd.',\n",
       " 'IBM India Pvt. Limited',\n",
       " 'Flipkart Internet Private Limited',\n",
       " 'McAfee Software (India) Pvt. Ltd',\n",
       " 'Snaphunt',\n",
       " 'Blisaura Events Studio Pvt Ltd',\n",
       " 'reach52',\n",
       " 'Liventus, Inc.',\n",
       " 'Encora']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping the company-name\n",
    "comp=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "\n",
    "for i in comp:\n",
    "    c=i.text\n",
    "    Company_Name.append(c)\n",
    "Company_Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0-3 Yrs',\n",
       " '6-11 Yrs',\n",
       " '2-3 Yrs',\n",
       " '6-9 Yrs',\n",
       " '2-7 Yrs',\n",
       " '3-4 Yrs',\n",
       " '5-8 Yrs',\n",
       " '2-4 Yrs',\n",
       " '2-5 Yrs',\n",
       " '5-10 Yrs',\n",
       " '1-3 Yrs',\n",
       " '5-10 Yrs',\n",
       " '5-8 Yrs',\n",
       " '2-4 Yrs',\n",
       " '4-7 Yrs',\n",
       " '3-5 Yrs',\n",
       " '2-5 Yrs',\n",
       " '4-6 Yrs',\n",
       " '3-6 Yrs',\n",
       " '4-9 Yrs']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping the experience required\n",
    "exp=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span\")\n",
    "\n",
    "for i in exp:\n",
    "    e=i.text\n",
    "    Experience_Required.append(e)\n",
    "Experience_Required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JOB_TITLE</th>\n",
       "      <th>JOB_LOCATION</th>\n",
       "      <th>COMPANY_NAME</th>\n",
       "      <th>EXPERIENCE_REQUIRED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist/Data Analyst-immediate</td>\n",
       "      <td>Chennai, Pune, Bengaluru, Hyderabad</td>\n",
       "      <td>CAIA-Center For Artificial Intelligence &amp; Adva...</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Applied Materials</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Mumbai, Bengaluru, Hyderabad</td>\n",
       "      <td>Cognizant Technology Solutions India Pvt Ltd</td>\n",
       "      <td>2-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID&amp;A - Data Analyst - Informatica MDM</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Shell India Markets Private Limited</td>\n",
       "      <td>6-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>GlaxoSmithKline Pharmaceuticals Limited</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bengaluru, Kolkata</td>\n",
       "      <td>Cognizant Technology Solutions India Pvt Ltd</td>\n",
       "      <td>3-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Shell India Markets Private Limited</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst - O2C - Bangalore</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>RANDSTAD INDIA PVT LTD</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Business Data Analyst - Database Design/Mining</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>AugmatrixGo</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst - MySQL/PostgreSQL</td>\n",
       "      <td>Pune, Mumbai, Bengaluru, Hyderabad, Noida, Jaipur</td>\n",
       "      <td>Astegic</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        JOB_TITLE  \\\n",
       "0           Data Scientist/Data Analyst-immediate   \n",
       "1                                    Data Analyst   \n",
       "2                                    Data Analyst   \n",
       "3           ID&A - Data Analyst - Informatica MDM   \n",
       "4                                    Data Analyst   \n",
       "5                                    Data Analyst   \n",
       "6                                    Data Analyst   \n",
       "7                  Data Analyst - O2C - Bangalore   \n",
       "8  Business Data Analyst - Database Design/Mining   \n",
       "9                 Data Analyst - MySQL/PostgreSQL   \n",
       "\n",
       "                                        JOB_LOCATION  \\\n",
       "0                Chennai, Pune, Bengaluru, Hyderabad   \n",
       "1                                          Bengaluru   \n",
       "2                       Mumbai, Bengaluru, Hyderabad   \n",
       "3                                          Bengaluru   \n",
       "4                                          Bengaluru   \n",
       "5                                 Bengaluru, Kolkata   \n",
       "6                                          Bengaluru   \n",
       "7                                          Bengaluru   \n",
       "8                                          Bengaluru   \n",
       "9  Pune, Mumbai, Bengaluru, Hyderabad, Noida, Jaipur   \n",
       "\n",
       "                                        COMPANY_NAME EXPERIENCE_REQUIRED  \n",
       "0  CAIA-Center For Artificial Intelligence & Adva...             0-3 Yrs  \n",
       "1                                  Applied Materials            6-11 Yrs  \n",
       "2       Cognizant Technology Solutions India Pvt Ltd             2-3 Yrs  \n",
       "3                Shell India Markets Private Limited             6-9 Yrs  \n",
       "4            GlaxoSmithKline Pharmaceuticals Limited             2-7 Yrs  \n",
       "5       Cognizant Technology Solutions India Pvt Ltd             3-4 Yrs  \n",
       "6                Shell India Markets Private Limited             5-8 Yrs  \n",
       "7                             RANDSTAD INDIA PVT LTD             2-4 Yrs  \n",
       "8                                        AugmatrixGo             2-5 Yrs  \n",
       "9                                            Astegic            5-10 Yrs  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a dataframe\n",
    "import pandas as pd\n",
    "Data_Analyst=pd.DataFrame({})\n",
    "Data_Analyst['JOB_TITLE']=Job_Title[0:10]\n",
    "Data_Analyst['JOB_LOCATION']=Job_Location[0:10]\n",
    "Data_Analyst['COMPANY_NAME']=Company_Name[0:10]\n",
    "Data_Analyst['EXPERIENCE_REQUIRED']=Experience_Required[0:10]\n",
    "Data_Analyst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, full job-description. You have to scrape first 10 jobs data. This task will be done in following steps: \n",
    "            \n",
    "1. first get the webpage https://www.naukri.com/ \n",
    "2. Enter “Data Scientist” in “Skill,Designations,Companies” field and enter “Bangalore” in “enter the location” field. \n",
    "3. Then click the search button. \n",
    "4. Then scrape the data for the first 10 jobs results you get. \n",
    "5. Finally create a dataframe of the scraped data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(executable_path=\"C:\\\\Users\\\\HP\\\\Downloads\\\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.naukri.com/data-scientist-jobs-in-bangalore?k=data%20scientist&l=bangalore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists for scraping data\n",
    "Job_Title=[]\n",
    "Job_Location=[]\n",
    "Company_Name=[]\n",
    "Job_Description=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist/Data Analyst-immediate',\n",
       " 'HCL hiring Data scientist with exp in machine learning &SQL-Bangalore!',\n",
       " 'Data Scientist -Machine Learning',\n",
       " 'Data Scientist - Machine Learning',\n",
       " 'Data Scientist - Machine Learning',\n",
       " 'Data Scientist - Machine Learning',\n",
       " 'Data Scientist - Machine Learning - Remote Working',\n",
       " 'Lead Data Scientist - Complete Remote Work',\n",
       " 'Data Scientist (Healthcare/Pharma Domain preferred)',\n",
       " 'Data Scientist',\n",
       " 'AI Resident - Data Scientist',\n",
       " 'Tech Mahindra hiring For Data Scientist- Bangalore',\n",
       " 'Senior Data Scientist',\n",
       " 'Lead Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Lead Data Scientist - Bangalore /Banking & Financial Domain is must',\n",
       " 'Data Scientist (machine Learning /AI)',\n",
       " 'Sr. Data Scientist',\n",
       " 'Sr Data Scientist - Python | Talent500',\n",
       " 'Sr . Data Scientist']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping the job-titles\n",
    "title=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "\n",
    "for i in title:\n",
    "    titles=i.text\n",
    "    Job_Title.append(titles)\n",
    "Job_Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chennai, Pune, Bengaluru, Hyderabad',\n",
       " 'Bengaluru',\n",
       " 'Bengaluru',\n",
       " 'Bengaluru',\n",
       " 'Bengaluru',\n",
       " 'Bengaluru',\n",
       " 'Delhi NCR, Bengaluru, Anywhere in India',\n",
       " 'Chennai, Pune, Delhi NCR, Mumbai, Bengaluru, Hyderabad',\n",
       " 'Bengaluru',\n",
       " 'Bengaluru',\n",
       " 'Bengaluru',\n",
       " 'Bengaluru',\n",
       " 'Mumbai, Bengaluru',\n",
       " 'Chennai, Mumbai, Bengaluru, Hyderabad',\n",
       " 'Bengaluru',\n",
       " 'Bengaluru',\n",
       " 'Delhi NCR, Mumbai, Bengaluru',\n",
       " 'Bengaluru',\n",
       " 'Bengaluru',\n",
       " 'Bengaluru']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping the job-location\n",
    "loc=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span\")\n",
    "\n",
    "for i in loc:\n",
    "    loca=i.text\n",
    "    Job_Location.append(loca)\n",
    "Job_Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CAIA-Center For Artificial Intelligence & Advanced Analytics',\n",
       " 'HCL Technologies Limited',\n",
       " 'BLUE YONDER INDIA PRIVATE LIMITED',\n",
       " 'AugmatrixGo',\n",
       " 'BLUE YONDER INDIA PRIVATE LIMITED',\n",
       " 'BLUE YONDER INDIA PRIVATE LIMITED',\n",
       " 'Doji Ltd',\n",
       " 'Techolution India Private Limited',\n",
       " 'GENPACT India Private Limited',\n",
       " '24/7 Customer',\n",
       " 'Shell India Markets Private Limited',\n",
       " 'tech mahindra ltd',\n",
       " 'UpGrad',\n",
       " 'Leading Data Science Firm',\n",
       " 'Applied Materials',\n",
       " 'Societe Generale',\n",
       " 'Mastermind Network',\n",
       " 'Blackhawk Network',\n",
       " 'ANSR GLOBAL CORPORATION PRIVATE LIMITED',\n",
       " 'Bidgely Technologies Private Limited']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping the company name\n",
    "comp=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "\n",
    "for i in comp:\n",
    "    c=i.text\n",
    "    Company_Name.append(c)\n",
    "Company_Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the job-description\n",
    "from selenium.common.exceptions import  NoSuchElementException\n",
    "urls=[]\n",
    "for i in driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\"):\n",
    "    urls.append(i.get_attribute(\"href\"))\n",
    "\n",
    "for url in urls[0:10]:\n",
    "    \n",
    "    try:\n",
    "        driver.get(url)\n",
    "        description=driver.find_element_by_xpath(\"//section[@class='job-desc']\").text\n",
    "        Job_Description.append(description)\n",
    "    except NoSuchElementException :\n",
    "        Job_Description.append(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Job description\\nDear Candidate\\n\\nSchedule a Telephonic Interview ( Please call for confirmation) : Mon- Sat from 11:00am to 5:00pm\\n\\nOR Walk-In to the Corporate office between Monday to Friday from 11:00am to 5:00pm\\nContact person :\\n\\nManigandan -+91 7299917200\\nShantha +91 9790993237\\n\\n\\nSystech Solutions\\nTemple Steps\\nTower 3, 6th Floor\\n184-187 Anna Salai\\nSaidapet, Chennai 600015\\nIndia (Near Little Mount Metro Station)\\nRoles and Responsibilities\\n\\nGreetings from CAIA !\\nA great opportunity to enter the world of future technologies - Data Science, Analytics, AI, Data Visualization\\nApplications invited from all Freshers and experienced candidates aspiring to make a career in Artificial Intelligence and Advanced Analytics and Data Science.\\nIn case you are trying to shift your career to Analytics and/or AI domain please do connect with us to know more.\\nWhat is needed from you?\\n- An Educational background in any one of the following- BE/B.Tech, ME/M Tech, MSc, BSc/MSc Maths and Statistics, B Com, BCA, BSc CS, BSC IT, MSC IT, MCA\\n- Skills relating to Mathematics/Statistics.\\n- Natural passion towards numbers, business, coding, Analytics and Artificial Intelligence, Machine Learning, visualization\\n- Good verbal and written communication skills\\n- Ability to understand domains in businesses across various sectors\\n- Freshers who wish to start their career in Analytics and AI and professionals who wish to up skill or change their domain to analytics and emerging technologies are free to apply.\\nSelection procedure includes\\n- Online Aptitude Test\\n- Logical Ability Test / Written Test\\nOn being shortlisted, you will be have to undergo a one-one discussion with our counsellor for further evaluation and processing of your Resume.\\nWhat you can expect from us?\\nYou will get trained on the following modules for a period of 12-14 weeks:\\n-SQL & PLSQL\\n-Data Wrangling using Python\\n-Statistics for Machine Learning,\\n-Artificial Intelligence, Data Interpretation\\n-Supervised & Unsupervised Learning,\\n-NLP & Deep Learning\\n-Cloud Data Lake\\n-Business intelligence & Data Visualization\\n-Simulation Projects\\nWhat is the expected Outcome?\\nAt the end of the Training you are expected to be well versed with the following:\\n- Analysis of large and complex data sets from multiple sources\\n- Development and evaluation of data analytics models, algorithms and solutions\\n- Understanding/implementation of ML algorithms, performance tuning and reporting\\n- Implementation of algorithms to mine targeted data and the ability to convert data into a business story\\n- Translation of business requirements into technical requirements; Data extraction, preparation and transformation\\n- Identification, development and implementation of statistical techniques and algorithms that address business challenges and adds value to the organisation\\n- Requirement Analysis and communication of findings in the form of a meaningful story with the stakeholders\\nCenter for Artificial Intelligence & Advanced Analytics (CAIA) focuses on the following:\\n1. Global Research on emerging trends, technologies and applications in AI and Advanced Analytics\\n2. Advanced Training programs for readying the future ready workforce\\n3. Solutions to herald the futuristic lifestyle and workspaces in the field of AI and Data Science.\\nhttp://www.centerforaia.com/\\nCenter for Artificial Intelligence and Advanced Analytics (Center for AIA) is the brainchild of experienced and visionary alumni of IIT Madras and Bombay. Digital leaders 5F World and Systech Solutions have joined hands to create a venture for architecting the future of society, workforce, governments and businesses. 5F World specializes in designing solutions around digital platforms and Systech Solutions has an expertise in architecting Artificial Intelligence and Advanced Analytics solutions for Fortune 500 companies through specialized programmed.\\n5F World\\n5F World is a leader in digital transformational journeys and has brought together the best minds in industry, academia and technology domains to develop a unique framework to transform stakeholder journeys through innovation and digitalization of businesses and education institutions.\\nSystech Solutions\\nSystech Solutions is a leading organisation in Data Strategy, Management & Analytics services provider with deep technology expertise and over 20 years of industry experience. Systech Solutions helps empower clients with innovative, data-driven solutions to reimagine their enterprise and has forged partnerships with industry-leading technology providers to develop a full spectrum of data services.\\n\\nWebsite\\nhttp://www.centerforaia.com/\\n\\nhttps://inflexion-analytix-private-limited.business.site/?m=true\\n\\n\\n\\nContact Person\\nShantha/Manigandan\\nPhone Number\\n9790993237 / 7299917200\\nEmail\\nmanigandan@centerforaia.com\\n\\nDesired Candidate Profile\\n\\nPerks and Benefits\\n\\nRoleBusiness Analyst\\nIndustry TypeBPO, Call Centre, ITeS\\nFunctional AreaIT Software - DBA, Datawarehousing\\nEmployment TypeFull Time, Permanent\\nRole CategorySystem Design/Implementation/ERP/CRM\\nEducation\\nUG :Other Graduate, Any Graduate in Any Specialization, B.Com in Any Specialization, Diploma in Any Specialization, B.Sc in Any Specialization, B.Tech/B.E. in Any Specialization\\nPG :M.Com in Any Specialization, MCA in Any Specialization, M.Tech in Any Specialization, PG Diploma in Any Specialization, MBA/PGDM in Any Specialization, MS/M.Sc(Science) in Any Specialization, Post Graduation Not Required, Other\\nKey Skills\\nBusiness IntelligenceArtificial IntelligenceNatural Language ProcessingNeural NetworksData MiningMachine LearningDeep LearningSQLData ScienceRNLPCloud ComputingData AnalysisPLSQLData WarehousingETLPredictive AnalyticsPython',\n",
       " \"Job description\\nDear Candidate,\\n\\nGreetings from HCL!!!\\nWe are looking for Data scientists with experience in machine learning algorithms and strong SQL experience.\\nIf you are Keen with Below Skill Set. Please do send the Updated CV with details such as current ctc, expected ctc and notice period to m_divvya@hcl.com / 8754448290.We are looking only for immediate joiners. Candidates with more than 30 days notice please don't apply.\\n\\n\\nTechnical Skills:\\nOverall 5+ years of experience in advanced analytics and leading/mentoring team members\\nProficient in Python & SQL with minimum 2-3 years of hands on experience\\nSolid fundamentals, knowledge of supervised, unsupervised, reinforcement learning machine learning and deep learning algorithms, such as classifiers, cluster analysis, dimension reduction, regression, CNN, RNN, DQN, temporal difference methods, sequence modeling, probability theory, algorithm design and theory of computation, information retrieval\\nAbility to work and execute projects on both structured and unstructured data in a big data environment • Strong at preparing data for analysis using SQL and experience working with the industry leading BI tools like Tableau, visualizing the data and executing to specifications\\nExperience of end to end implementation of predictive analytics projects for at least 1-3 years • Exposure to text analytics, web scraping, big data technologies and graph databases would be desirable • Exposure to visualization tools • Experience of intent to learn software domain related to VMware products and the way virtualization software/hardware\\n\\nPreferred Skills:\\nGood understanding of API connections and data pipelining • Knowledge with Natural Language Processing (e.g. word2vec, doc2vec, attention, LDA) • Understanding of different model performance metrics and hyperparameter optimization • Business Acumen, ability to translate business needs into a set of workable, specific requirements • Well versed with MS PowerPoint/Visio\\nAbility to understand business requirements, KPIs and convert into analytical hypothesis in a structured and logical manner along with solution identification • Ability to handle multiple projects at a time in terms of multitasking, prioritization, allocation and team management • Ability to coordinate and work within multiple business units from project management perspective • Ability to work across geographies and interact with global stakeholders • Prior experience working in Agile methodologies/JIRA would be a plus\\nWhat we are looking for:\\nBS/BE in Computer Sciences, Math, Statistics or related field. Masters preferred.\\nProficient in SQL and experience with efficient processing of large data sets. Ability to write sophisticated and optimized queries against large databases • Proficient in data visualization tools such as Mode Analytics or Tableau • Proficient in Excel • Experience in statistical computing with Python/R • Ability to handle several concurrent activities with strong organizational skills and attention to detail We're team players. You'll do well if you're one too\\nRoleIT/Technical Content Developer\\nIndustry TypeIT-Software, Software Services\\nFunctional AreaIT Software - Application Programming, Maintenance\\nEmployment TypeFull Time, Permanent\\nRole CategoryOther\\nEducation\\nUG :B.Tech/B.E. in Any Specialization\\nKey Skills\\nMachine LearningSQL\",\n",
       " '---',\n",
       " 'Job description\\nRoles and Responsibilities\\n\\n\\n- Selecting features, building and optimizing classifiers using machine learning techniques\\n\\n- Data mining using state-of-the-art methods\\n\\n- Enhancing data collection procedures to include information that is relevant for building analytic systems\\n\\n- Processing, cleansing, and verifying the integrity of data used for analysis\\n\\n- Doing ad-hoc analysis and presenting results in a clear manner\\n\\n- Creating automated anomaly detection systems and constant tracking of its performance\\n\\nSkills Required :\\n\\n- Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc.\\n\\n- Experiences with one or more of the following is highly desirable: HPC/Parallelization, operationalizing ML models; cloud computing (e.g. Google Cloud, AWS, etc.); familiarity with ML frameworks such as Tensorflow, Theano, MXNet, etc\\n\\n- Good experience in a few of the following areas: deep neural networks, reinforcement learning, Markov Random Fields, Bayesian networks, semi-supervised learning, computer vision, image processing, signal processing, distributed computing, and/or numerical optimization\\n\\n- 2+ years of experience with computer vision and deep learning solutions, including image classification, object detection, segmentation, and equivalent computer vision-based vision tasks\\n\\n- Experience with common data science toolkits, such as R, Weka, NumPy, etc . Excellence in at least one of these is highly desirable\\n\\n- Proficiency in using query languages such as SQL, Hive, Pig\\n\\n- Good applied statistics skills, such as distributions, statistical testing, regression, etc.\\n\\n- Good scripting and programming skills\\n\\n- Data-oriented personality\\n\\n- B.Tech/M.Tech degree in from reputed institutes like IIT / NIT / BITS\\nRoleData Analyst\\nIndustry TypeIT-Software, Software Services\\nFunctional AreaAnalytics & Business Intelligence\\nEmployment TypeFull Time, Permanent\\nRole CategoryAnalytics & BI\\nEducation\\nUG :B.Tech/B.E. in Any Specialization\\nPG :M.Tech in Any Specialization\\nDoctorate :Doctorate Not Required\\nKey Skills\\nHiveRCloud ComputingData ScientistComputer VisionMachine LearningDeep LearningSQLPig',\n",
       " '---',\n",
       " '---',\n",
       " \"Job description\\nPlease note that this role will be Remote / Home-based for next 6 to 12 months.\\n\\nIn DOJI, we are building a next generation marketplace and setting new standards for e-commerce buyers and sellers worldwide. We are a UK based tech start-up, founded by three passionate entrepreneurs with a track record of building and exiting successful ventures.\\nWe're excited to build this world-class team that is going to reshape the way people buy and sell consumer goods.\\n\\nRoles and Responsibilities\\n\\nPerform exploratory and statistical analyses to understand and predict our customer behaviours, identify bottlenecks, and answer critical business questions.\\nBuild and deploy scalable machine learning models and oversee their performance against KPIs.\\nForecast our users conversion, engagement, and churn with rigorous statistical models\\nBuild overall data capability of our organisation by performing complex data processing, building data pipelines and developing data products which can be directly used by our business users such as marketing and product teams\\n\\nRequirements\\n\\nFollowing are the mandatory skills & experience requirements for this role:\\nBeen a data scientist for 2+ years in a commercial set-up\\nDirect experience in performing statistical analyses or building a variety of machine learning models from complex, specialised or large data pools.\\nPassion for understanding user behaviour and building solutions to optimise customer experience and growth.\\nDemonstrated competency with unsupervised machine learning algorithms (k-means clustering, isolation forests etc.) and / or supervised algorithms (logistic regression, SVM, Random Forests, GBM etc.)\\nDirect experience using programming languages such as Python or R for statistical and/or numeric computing\\nUndergraduate degree in a quantitative discipline (maths, statistics, econometrics etc.) or computer science\\n\\nAlthough the following requirements are not mandatory, however we would strongly prefer candidates with this skill and experience.\\nWe would prefer someone who also has experience in: data engineering, building data pipelines and cloud (AWS, Azure or GCP).\\nExperience with additional programming languages used for data processing such as SQL, Hive, PySpark, Scala etc.\\nExperience with consumer retail or e-commerce data\\nPostgraduate degree in a quantitative discipline or computer science\\n\\nPerks and Benefits\\n\\nA very competitive package of 15 to 20 Lacs\\nBe part of a start-up with an entrepreneurial mindset that thinks big, with a long-term vision.\\nBe the owner of your own development in an environment that is full of opportunities, learning, growth, expansion and challenging projects.\\nShare and learn with the team, amongst great professionals and experts.\\nAn excellent work environment, with everything that you need to enjoy a great experience\\n\\nSince this role will be 'Remote' (e.g. home office) during the initial stages, you will be responsible to ensure proper working conditions (computer and related equipment, reliable internet connection, etc) and availability during normal business working hours. As per business needs, you could be asked to work from an office based office location in the future.\\nIn Doji, we work hard to promote a culture of inclusiveness and diversity that seeks equality and values from different perspectives. We believe in building trust and fairness amongst people and making a positive impact on the environment.\\nShould you require reasonable adjustments throughout the hiring process, please don't hesitate to get in touch with us.\\nRoleData Analyst\\nIndustry TypeInternet, Ecommerce\\nFunctional AreaAnalytics & Business Intelligence\\nEmployment TypeFull Time, Permanent\\nRole CategoryAnalytics & BI\\nEducation\\nUG :Any Graduate in Any Specialization\\nKey Skills\\nData ScienceMachine LearningPython\\nPysparkRHiveLogistic RegressionData Engineeringdata scientistSVMStatisticsSQL\\nSkills highlighted with ‘‘ are preferred keyskills\",\n",
       " \"Job description\\n\\nWe are looking for qualified Lead Data Scientist, who can independently drive Data Science initiatives and manage the data science team, planning projects and building analytics models.\\n\\nTitle : Lead Data Scientist\\nLocation: Complete Remote work\\nPlease note , We are looking for someone who can travel to Mauritius on the need basis.\\n\\nJob Responsibilities:\\nDefine the Advanced Analytics Roadmap and drive the execution of same to drive business value for the organization.\\nCoach the Analytics team on state-of-the-art advanced analytic, quantitative tools and modeling techniques required to derive business insights, solve complex business problems and improve decisions.\\nPartner with the Analytics Translator lead to facilitate strategic workshops with Business Leaders to identify opportunities for leveraging company data to drive business solutions.\\nSet up the advanced analytics environment that will enable the sustainable execution of the analytics roadmap (including exploring cloud and on-premise solutions such as Hadoop).\\nMake daily prioritization decisions on data sources and environment capabilities accordance the roadmap.\\nOversee the portfolio of analytics projects to ensure alignment and consistency across.\\nDevelop standards and processes for analytics solution development and implementation across all critical functions of the company.\\nOversee processes for extracting, analyzing and interpreting data to ensure that data integrity and accuracy prior to the development of analytical models.\\nCollaborate with software engineers to map, produce, transform and test new data feeds for data owners and end-users\\nInstill a culture of data-informed decision making across the bank by championing broader analytics initiatives across the Bank.\\nOversee the quality and effectiveness of analytics models deployed across the bank.\\nEnsure optimal staffing across analytics use cases and customer journey squads.\\nSet up a community of practice for data practitioners to explore new techniques/ technologies to ensure sustained learning and growth.\\nProvide thought leadership by researching best practices, conducting experiments and staying abreast of latest trends in analytical techniques such as machine learning, deep learning and text analytics to drive continuous innovative.\\nQualifications & Experience:\\nAdvanced degree in Computer Science, Economics, Mathematics)\\n7-10 years experience in analytics of which at least 5 years in a team leadership position\\nDeep rooted knowledge and understanding of analytics tools (e.g. SAS, R, Hadoop) & advanced modeling techniques (e.g. random forests, time series etc.)\\nGood knowledge of data structures and databases (e.g. Teradata), database management softwares (e.g. SQL, Sybase) & workflow integrations with different systems (e.g. CRM, Finacle)\\nPrior experience in model development & maintenance for acquisition, underwriting and collections based use cases is an added plus\\nWhy Join Techolution?\\nBe part of the next most admired high tech brand in the world and launch the next most exciting billion-dollar IPO. We are looking for talent with amazing technical skills with a great foundation for the open role. The type of personality which do very well at our company are people who are looking to contribute a larger than life cause. People who are looking for a very high growth environment where they are helping the company grow and also personally growing through a very unique and world-class exposure.\\nWork-Life at Techolution:\\nAt Techolution, we do things a bit differently. There's no corporate nonsense, and no old-fashioned hierarchy. Instead, we work in dozens of self-sufficient, autonomous teams. Think of them like start-ups within a start-up that learn from each other. You are your own boss! We're going to be upfront, the way we work doesn't suit everyone. But if freedom, autonomy, and life-affirming, head-scratching professional challenges rock your world, we could be a match made in heaven.\\nWhy Join Techolution?\\nBe part of the next most admired high tech brand in the world and launch the next most exciting billion dollar IPO. We are looking for talent with amazing technical skills with a great foundation for the open role. The type of personalities that do very well at our company are people who are looking to contribute to a larger than life cause. People who are looking for a very high growth environment where they are helping the company grow and also personally growing through a very unique and world-class exposure.\\nWork Life at Techolution:\\nAt Techolution, we do things a bit differently. There's no corporate nonsense, and no old-fashioned hierarchy. Instead, we work in dozens of self-sufficient, autonomous teams. Think of them like start-ups within a start-up that learn from each other. You are your own boss! We're going to be upfront the way we work doesn't suit everyone. But if freedom, autonomy, and life-affirming, head-scratching professional challenges rock your world, we could be a match made in heaven.\\n\\nRegards,\\nMadhav\\nMadhav@techolution.com\\nRoleAnalytics Manager\\nIndustry TypeBanking, Financial Services, Broking\\nFunctional AreaAnalytics & Business Intelligence\\nEmployment TypeFull Time, Permanent\\nRole CategoryAnalytics & BI\\nEducation\\nUG :Any Graduate in Any Specialization\\nKey Skills\\nData ScienceRArtificial IntelligenceAdvanced AnalyticsTime SeriesMachine LearningModel Development\",\n",
       " '---',\n",
       " 'Job description\\nAs a data scientist, you d be working towards developing cutting edge products and solutions that are based on state of the art machine learning algorithms. You will be joining the 247s core R&D team, which is based in Bangalore. The core R&D team works on real-world challenging problems in the NLP and Conversational AI domain.\\nWe need a Data scientist who have experience in building deep learning models for NLP using Tensorflow .\\nSome of the attractive pluses of the job are:\\nThe opportunity to work with a world class team of talented data scientists with strong background in machine learning, and who are extremely passionate about solving real-world applied problems in the web-analytics domain.\\nA real opportunity to expand your skill-sets and a chance to learn and use the latest advances and approaches in machine learning and data mining on real world datasets\\nA big plus is the opportunity to play and work with what are really big-data datasets.\\nWorking in a university like work-environment where you are expected to be self-motivated and are measured on your performance.\\nDetailed Description:\\nIn this role, you will be required to have the following skills:\\nIntermediate to advanced knowledge of machine learning, probability theory, statistics and algorithms. You will be required to discuss and use various algorithms and approaches on a daily basis.\\nStrong programming skills: Since most of the core R&D teams work involves solving problems in the big-data domain, preparing datasets for algorithmic exploration is a significant part of the job. You should have strong programming skills (preferably in python), in order to play around with the raw data, and also for deploying various algorithms\\nStrong analytical skills: We seek individuals who try to look at a problem from various angles, and who have deep analytical skills to understand, grasp and discuss deeply technical and significantly complicated problems, and the solutions that the R&D team is working on.\\nEducational Qualification & Work Experience\\nCandidates from a reputable institution like IITs, IISc, or equivalent\\n2-4 years of work experience in machine learning and data mining domain, where you have been actively involved in industry research.\\nRoleBio-Statistician\\nIndustry TypeIT-Software, Software Services\\nFunctional AreaMedical, Healthcare, R&D, Pharmaceuticals, Biotechnology\\nEmployment TypeFull Time, Permanent\\nRole CategoryR&D\\nEducation\\nUG :B.Tech/B.E. in Any Specialization\\nPG :Post Graduation Not Required\\nKey Skills\\nAnalytical skillsIndustry researchdata domainWeb analyticsMachine learningProgrammingData miningbig dataPython']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Job_Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JOB_TITLE</th>\n",
       "      <th>JOB_LOCATION</th>\n",
       "      <th>COMPANY_NAME</th>\n",
       "      <th>JOB_DESCRIPTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist/Data Analyst-immediate</td>\n",
       "      <td>Chennai, Pune, Bengaluru, Hyderabad</td>\n",
       "      <td>CAIA-Center For Artificial Intelligence &amp; Adva...</td>\n",
       "      <td>Job description\\nDear Candidate\\n\\nSchedule a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HCL hiring Data scientist with exp in machine ...</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>HCL Technologies Limited</td>\n",
       "      <td>Job description\\nDear Candidate,\\n\\nGreetings ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist -Machine Learning</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>BLUE YONDER INDIA PRIVATE LIMITED</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist - Machine Learning</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>AugmatrixGo</td>\n",
       "      <td>Job description\\nRoles and Responsibilities\\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist - Machine Learning</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>BLUE YONDER INDIA PRIVATE LIMITED</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist - Machine Learning</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>BLUE YONDER INDIA PRIVATE LIMITED</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist - Machine Learning - Remote Wor...</td>\n",
       "      <td>Delhi NCR, Bengaluru, Anywhere in India</td>\n",
       "      <td>Doji Ltd</td>\n",
       "      <td>Job description\\nPlease note that this role wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lead Data Scientist - Complete Remote Work</td>\n",
       "      <td>Chennai, Pune, Delhi NCR, Mumbai, Bengaluru, H...</td>\n",
       "      <td>Techolution India Private Limited</td>\n",
       "      <td>Job description\\n\\nWe are looking for qualifie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist (Healthcare/Pharma Domain prefe...</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>GENPACT India Private Limited</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>24/7 Customer</td>\n",
       "      <td>Job description\\nAs a data scientist, you d be...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           JOB_TITLE  \\\n",
       "0              Data Scientist/Data Analyst-immediate   \n",
       "1  HCL hiring Data scientist with exp in machine ...   \n",
       "2                   Data Scientist -Machine Learning   \n",
       "3                  Data Scientist - Machine Learning   \n",
       "4                  Data Scientist - Machine Learning   \n",
       "5                  Data Scientist - Machine Learning   \n",
       "6  Data Scientist - Machine Learning - Remote Wor...   \n",
       "7         Lead Data Scientist - Complete Remote Work   \n",
       "8  Data Scientist (Healthcare/Pharma Domain prefe...   \n",
       "9                                     Data Scientist   \n",
       "\n",
       "                                        JOB_LOCATION  \\\n",
       "0                Chennai, Pune, Bengaluru, Hyderabad   \n",
       "1                                          Bengaluru   \n",
       "2                                          Bengaluru   \n",
       "3                                          Bengaluru   \n",
       "4                                          Bengaluru   \n",
       "5                                          Bengaluru   \n",
       "6            Delhi NCR, Bengaluru, Anywhere in India   \n",
       "7  Chennai, Pune, Delhi NCR, Mumbai, Bengaluru, H...   \n",
       "8                                          Bengaluru   \n",
       "9                                          Bengaluru   \n",
       "\n",
       "                                        COMPANY_NAME  \\\n",
       "0  CAIA-Center For Artificial Intelligence & Adva...   \n",
       "1                           HCL Technologies Limited   \n",
       "2                  BLUE YONDER INDIA PRIVATE LIMITED   \n",
       "3                                        AugmatrixGo   \n",
       "4                  BLUE YONDER INDIA PRIVATE LIMITED   \n",
       "5                  BLUE YONDER INDIA PRIVATE LIMITED   \n",
       "6                                           Doji Ltd   \n",
       "7                  Techolution India Private Limited   \n",
       "8                      GENPACT India Private Limited   \n",
       "9                                      24/7 Customer   \n",
       "\n",
       "                                     JOB_DESCRIPTION  \n",
       "0  Job description\\nDear Candidate\\n\\nSchedule a ...  \n",
       "1  Job description\\nDear Candidate,\\n\\nGreetings ...  \n",
       "2                                                ---  \n",
       "3  Job description\\nRoles and Responsibilities\\n\\...  \n",
       "4                                                ---  \n",
       "5                                                ---  \n",
       "6  Job description\\nPlease note that this role wi...  \n",
       "7  Job description\\n\\nWe are looking for qualifie...  \n",
       "8                                                ---  \n",
       "9  Job description\\nAs a data scientist, you d be...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a dataframe\n",
    "import pandas as pd\n",
    "Data_Scientist=pd.DataFrame({})\n",
    "Data_Scientist['JOB_TITLE']=Job_Title[0:10]\n",
    "Data_Scientist['JOB_LOCATION']=Job_Location[0:10]\n",
    "Data_Scientist['COMPANY_NAME']=Company_Name[0:10]\n",
    "Data_Scientist['JOB_DESCRIPTION']=Job_Description[0:10]\n",
    "Data_Scientist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3: In this question you have to scrape data using the filters available on the webpage as shown below: \n",
    " \n",
    " \n",
    "You have to use the location and salary filter. You have to scrape data for “Data Scientist” designation for first 10 job results. You have to scrape the job-title, job-location, company_name, experience_required. The location filter to be used is “Delhi/NCR” The salary filter to be used is “3-6” lakhs The task will be done as shown in the below steps: \n",
    "    \n",
    "1. first get the webpage https://www.naukri.com/ \n",
    "2. Enter “Data Scientist” in “Skill,Designations,Companies” field . \n",
    "3. Then click the search button. \n",
    "4. Then apply the location filter and salary filter by checking the respective boxes \n",
    "5. Then scrape the data for the first 10 jobs results you get. \n",
    "6. Finally create a dataframe of the scraped data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(executable_path=\"C:\\\\Users\\\\HP\\\\Downloads\\\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.naukri.com/data-scientist-jobs-in-delhi-ncr?k=data%20scientist&l=delhi%2Fncr&ctcFilter=3to6\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists for scraping data\n",
    "Job_Title=[]\n",
    "Job_Location=[]\n",
    "Company_Name=[]\n",
    "Experience_Required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist - Python/Machine Learning',\n",
       " 'Data Scientist - Commercial Planning and Analysis',\n",
       " 'Data Scientist - Machine Learning/ Artificial Intelligence - IT',\n",
       " 'Tech Mahindra hiring For Data Scientist- Noida',\n",
       " 'GCP Skilled Analytics Resources (Data engineer / Data scientists)',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist Machine Learning',\n",
       " 'Data Scientist',\n",
       " 'Business Analyst - Data Scientist',\n",
       " 'Analyst - Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Only Fresher / Data Scientist / Data Analyst / Business Analytics- MNC',\n",
       " 'Senior Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Lead Data Scientist',\n",
       " 'Excellent opportunity For Lead Data Scientist at Noida location']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping the job-titles\n",
    "title=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "\n",
    "for i in title:\n",
    "    titles=i.text\n",
    "    Job_Title.append(titles)\n",
    "Job_Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Noida',\n",
       " 'Delhi NCR, Gurgaon',\n",
       " 'Delhi/NCR Delhi NCR, Noida',\n",
       " 'Noida',\n",
       " 'Pune, Bengaluru, Gurgaon',\n",
       " 'Gurgaon Gurugram',\n",
       " 'Gurgaon',\n",
       " 'Delhi NCR',\n",
       " 'Gurgaon',\n",
       " 'Gurgaon',\n",
       " 'Faridabad, Delhi NCR, Ghaziabad',\n",
       " 'Delhi NCR, Noida, Gurgaon',\n",
       " 'Delhi',\n",
       " 'Delhi',\n",
       " 'Delhi',\n",
       " 'Delhi',\n",
       " 'Gurgaon',\n",
       " 'Gurgaon',\n",
       " 'Delhi NCR, Noida(Sector-142 Noida)',\n",
       " 'Delhi NCR(Sector-142 Noida), Noida']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping the job-location\n",
    "loc=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span\")\n",
    "\n",
    "for i in loc:\n",
    "    loca=i.text\n",
    "    Job_Location.append(loca)\n",
    "Job_Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Jubna',\n",
       " 'Air Asia India Limited',\n",
       " 'Talent Acceleration Corridor',\n",
       " 'tech mahindra ltd',\n",
       " 'Aerial Telecom Solutions Pvt. Ltd.',\n",
       " 'IBM India Pvt. Limited',\n",
       " 'Delhivery',\n",
       " 'Eighteen Pixels India Private Limited',\n",
       " 'HyreFox Consultants Pvt Ltd',\n",
       " 'HyreFox Consultants Pvt Ltd',\n",
       " 'Amity University',\n",
       " 'GABA Consultancy services',\n",
       " 'iNICU',\n",
       " 'Sentieo',\n",
       " 'Mahajan Imaging',\n",
       " 'Mahajan Imaging',\n",
       " 'T & A Solutions',\n",
       " 'itForte Staffing Services Private Ltd.',\n",
       " 'NEC CORPORATION INDIA PRIVATE LTD',\n",
       " 'NEC CORPORATION INDIA PRIVATE LTD']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping the company name\n",
    "comp=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "\n",
    "for i in comp:\n",
    "    c=i.text\n",
    "    Company_Name.append(c)\n",
    "Company_Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5-8 Yrs',\n",
       " '1-6 Yrs',\n",
       " '6-11 Yrs',\n",
       " '5-10 Yrs',\n",
       " '3-8 Yrs',\n",
       " '3-5 Yrs',\n",
       " '1-3 Yrs',\n",
       " '2-6 Yrs',\n",
       " '3-5 Yrs',\n",
       " '1-3 Yrs',\n",
       " '6-8 Yrs',\n",
       " '0-0 Yrs',\n",
       " '1-5 Yrs',\n",
       " '2-7 Yrs',\n",
       " '2-6 Yrs',\n",
       " '2-6 Yrs',\n",
       " '1-6 Yrs',\n",
       " '3-8 Yrs',\n",
       " '9-14 Yrs',\n",
       " '9-14 Yrs']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping the experience required\n",
    "exp=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span\")\n",
    "\n",
    "for i in exp:\n",
    "    e=i.text\n",
    "    Experience_Required.append(e)\n",
    "Experience_Required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JOB_TITLE</th>\n",
       "      <th>JOB_LOCATION</th>\n",
       "      <th>COMPANY_NAME</th>\n",
       "      <th>EXPERIENCE_REQUIRED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist - Python/Machine Learning</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Jubna</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist - Commercial Planning and Analysis</td>\n",
       "      <td>Delhi NCR, Gurgaon</td>\n",
       "      <td>Air Asia India Limited</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist - Machine Learning/ Artificial ...</td>\n",
       "      <td>Delhi/NCR Delhi NCR, Noida</td>\n",
       "      <td>Talent Acceleration Corridor</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tech Mahindra hiring For Data Scientist- Noida</td>\n",
       "      <td>Noida</td>\n",
       "      <td>tech mahindra ltd</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GCP Skilled Analytics Resources (Data engineer...</td>\n",
       "      <td>Pune, Bengaluru, Gurgaon</td>\n",
       "      <td>Aerial Telecom Solutions Pvt. Ltd.</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon Gurugram</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist Machine Learning</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Delhivery</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi NCR</td>\n",
       "      <td>Eighteen Pixels India Private Limited</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Business Analyst - Data Scientist</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>HyreFox Consultants Pvt Ltd</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Analyst - Data Scientist</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>HyreFox Consultants Pvt Ltd</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           JOB_TITLE  \\\n",
       "0           Data Scientist - Python/Machine Learning   \n",
       "1  Data Scientist - Commercial Planning and Analysis   \n",
       "2  Data Scientist - Machine Learning/ Artificial ...   \n",
       "3     Tech Mahindra hiring For Data Scientist- Noida   \n",
       "4  GCP Skilled Analytics Resources (Data engineer...   \n",
       "5                                     Data Scientist   \n",
       "6                    Data Scientist Machine Learning   \n",
       "7                                     Data Scientist   \n",
       "8                  Business Analyst - Data Scientist   \n",
       "9                           Analyst - Data Scientist   \n",
       "\n",
       "                 JOB_LOCATION                           COMPANY_NAME  \\\n",
       "0                       Noida                                  Jubna   \n",
       "1          Delhi NCR, Gurgaon                 Air Asia India Limited   \n",
       "2  Delhi/NCR Delhi NCR, Noida           Talent Acceleration Corridor   \n",
       "3                       Noida                      tech mahindra ltd   \n",
       "4    Pune, Bengaluru, Gurgaon     Aerial Telecom Solutions Pvt. Ltd.   \n",
       "5            Gurgaon Gurugram                 IBM India Pvt. Limited   \n",
       "6                     Gurgaon                              Delhivery   \n",
       "7                   Delhi NCR  Eighteen Pixels India Private Limited   \n",
       "8                     Gurgaon            HyreFox Consultants Pvt Ltd   \n",
       "9                     Gurgaon            HyreFox Consultants Pvt Ltd   \n",
       "\n",
       "  EXPERIENCE_REQUIRED  \n",
       "0             5-8 Yrs  \n",
       "1             1-6 Yrs  \n",
       "2            6-11 Yrs  \n",
       "3            5-10 Yrs  \n",
       "4             3-8 Yrs  \n",
       "5             3-5 Yrs  \n",
       "6             1-3 Yrs  \n",
       "7             2-6 Yrs  \n",
       "8             3-5 Yrs  \n",
       "9             1-3 Yrs  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a dataframe\n",
    "import pandas as pd\n",
    "Data_Scientists=pd.DataFrame({})\n",
    "Data_Scientists['JOB_TITLE']=Job_Title[0:10]\n",
    "Data_Scientists['JOB_LOCATION']=Job_Location[0:10]\n",
    "Data_Scientists['COMPANY_NAME']=Company_Name[0:10]\n",
    "Data_Scientists['EXPERIENCE_REQUIRED']=Experience_Required[0:10]\n",
    "Data_Scientists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4: Write a python program to scrape data for first 10 job results for Data scientist Designation in Noida location. You have to scrape company_name, No. of days ago when job was posted, Rating of the company. This task will be done in following steps: \n",
    "        \n",
    "1. first get the webpage https://www.glassdoor.co.in/index.htm \n",
    "2. Enter “Data Scientist” in “Job Title,Keyword,Company” field and enter “Noida” in “location” field. \n",
    "3. Then click the search button. You will land up in the below page: \n",
    "4. Then scrape the data for the first 10 jobs results you get in the above shown page. \n",
    "5. Finally create a dataframe of the scraped data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(executable_path=\"C:\\\\Users\\\\HP\\\\Downloads\\\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.glassdoor.co.in/Job/noida-data-scientist-jobs-SRCH_IL.0,5_IC4477468_KO6,20.htm\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists for scraping data\n",
    "Company_Ratings=[]\n",
    "Company_Name=[]\n",
    "Days_Ago=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WSD Consultant',\n",
       " 'QuantumIT',\n",
       " 'HDFC Bank',\n",
       " 'Biz2Credit Inc',\n",
       " 'Techlive',\n",
       " 'ANI Calls India Private Limited',\n",
       " 'Simpplr Software India Pvt. Ltd.',\n",
       " 'Salasar New Age Technologies',\n",
       " 'Salasar New Age Technologies',\n",
       " 'SearchUrCollege',\n",
       " 'Dürr Somac GmbH',\n",
       " 'THSTI',\n",
       " 'ANI Calls India Private Limited',\n",
       " 'Agrex Technologies Private Limited',\n",
       " 'Black Console Technologies',\n",
       " 'Great Learning',\n",
       " 'Dürr AG',\n",
       " 'GreenTech Intelligent Transportation System LLP',\n",
       " 'Emerging India Group',\n",
       " 'Gauge Data Solutions',\n",
       " 'Priority Vendor',\n",
       " 'ANI Calls India Private Limited',\n",
       " 'xtLytics',\n",
       " 'ANI Calls India Private Limited',\n",
       " 'xtLytics',\n",
       " 'ANI Calls India Private Limited',\n",
       " 'Microsoft',\n",
       " 'IElevate Institute',\n",
       " 'ANI Calls India Private Limited',\n",
       " 'iGloble Solutions']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping the company name\n",
    "name=driver.find_elements_by_xpath(\"//a[@class=' css-10l5u4p e1n63ojh0 jobLink']/span\")\n",
    "\n",
    "for i in name:\n",
    "    nm=i.text\n",
    "    Company_Name.append(nm)\n",
    "Company_Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3.3',\n",
       " '3.7',\n",
       " '3.7',\n",
       " '5',\n",
       " '3.9',\n",
       " '4.2',\n",
       " '3.7',\n",
       " '3.1',\n",
       " '3.7',\n",
       " '3',\n",
       " '3',\n",
       " '4.4',\n",
       " '4']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping the ratings of company\n",
    "rat=driver.find_elements_by_xpath(\"//span[@class='compactStars ']\")\n",
    "\n",
    "for i in rat:\n",
    "    r=i.text\n",
    "    Company_Ratings.append(r)\n",
    "Company_Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['30d+',\n",
       " '16d',\n",
       " '3d',\n",
       " '30d+',\n",
       " '30d+',\n",
       " '24h',\n",
       " '1d',\n",
       " '30d+',\n",
       " '30d+',\n",
       " '30d+',\n",
       " '30d+',\n",
       " '22d',\n",
       " '30d+',\n",
       " '9d',\n",
       " '7d',\n",
       " '14d',\n",
       " '30d+',\n",
       " '12d',\n",
       " '26d',\n",
       " '30d+',\n",
       " '30d+',\n",
       " '30d+',\n",
       " '30d+',\n",
       " '30d+',\n",
       " '30d+',\n",
       " '30d+',\n",
       " '30d+',\n",
       " '8d',\n",
       " '30d+',\n",
       " '16d']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping the no. of days ago the job was posted \n",
    "day=driver.find_elements_by_xpath(\"//div[@class='d-flex align-items-end pl-std css-mi55ob']\")\n",
    "\n",
    "for i in day:\n",
    "    days=i.text\n",
    "    Days_Ago.append(days)\n",
    "Days_Ago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Company_Ratings</th>\n",
       "      <th>Days_Ago</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WSD Consultant</td>\n",
       "      <td>3.3</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QuantumIT</td>\n",
       "      <td>3.7</td>\n",
       "      <td>16d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HDFC Bank</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Biz2Credit Inc</td>\n",
       "      <td>5</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Techlive</td>\n",
       "      <td>3.9</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ANI Calls India Private Limited</td>\n",
       "      <td>4.2</td>\n",
       "      <td>24h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Simpplr Software India Pvt. Ltd.</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Salasar New Age Technologies</td>\n",
       "      <td>3.1</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Salasar New Age Technologies</td>\n",
       "      <td>3.7</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SearchUrCollege</td>\n",
       "      <td>3</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Company_Name Company_Ratings Days_Ago\n",
       "0                    WSD Consultant             3.3     30d+\n",
       "1                         QuantumIT             3.7      16d\n",
       "2                         HDFC Bank             3.7       3d\n",
       "3                    Biz2Credit Inc               5     30d+\n",
       "4                          Techlive             3.9     30d+\n",
       "5   ANI Calls India Private Limited             4.2      24h\n",
       "6  Simpplr Software India Pvt. Ltd.             3.7       1d\n",
       "7      Salasar New Age Technologies             3.1     30d+\n",
       "8      Salasar New Age Technologies             3.7     30d+\n",
       "9                   SearchUrCollege               3     30d+"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a dataframe\n",
    "import pandas as pd\n",
    "Data_scientist=pd.DataFrame({})\n",
    "Data_scientist['Company_Name']=Company_Name[0:10]\n",
    "Data_scientist['Company_Ratings']=Company_Ratings[0:10]\n",
    "Data_scientist['Days_Ago']=Days_Ago[0:10]\n",
    "Data_scientist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5: Write a python program to scrape the salary data for Data Scientist designation in Noida location. You have to scrape Company name, Number of salaries, Average salary, Min salary, Max Salary. The above task will be, done as shown in the below steps: \n",
    "        \n",
    "1. first get the webpage https://www.glassdoor.co.in/Salaries/index.htm \n",
    "2. Enter “Data Scientist” in Job title field and “Noida” in location field. \n",
    "3. Click the search button. \n",
    "4. After that you will land on the below page  \n",
    "You have to scrape whole data from this webpage\n",
    "5. Scrape data for first 10 companies. Scrape the min salary, max salary, company name, Average salary and rating of the company. \n",
    "6.Store the data in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(executable_path=\"C:\\\\Users\\\\HP\\\\Downloads\\\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.glassdoor.co.in/Salaries/new-delhi-data-scientist-salary-SRCH_IL.0,9_IM1083_KO10,24.htm?clickSource=searchBtn\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists for scraping data\n",
    "Min_Salary=[]\n",
    "Max_Salary=[]\n",
    "Average_Salary=[]\n",
    "Company_Name=[]\n",
    "Rating=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹456K',\n",
       " '₹420K',\n",
       " '₹585K',\n",
       " '₹336K',\n",
       " '₹595K',\n",
       " '₹727K',\n",
       " '₹509K',\n",
       " '₹629K',\n",
       " '₹804K',\n",
       " '₹205K',\n",
       " '₹985K',\n",
       " '₹583K',\n",
       " '₹819K',\n",
       " '₹1,554K',\n",
       " '₹829K',\n",
       " '₹87K',\n",
       " '₹478K',\n",
       " '₹936K',\n",
       " '₹641K',\n",
       " '₹1,442K']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping the minimum salary\n",
    "min=driver.find_elements_by_xpath(\"//div[@class='common__RangeBarStyle__values common__flex__justifySpaceBetween common__flex__container ']/span[1]\")\n",
    "\n",
    "for i in min:\n",
    "    mi=i.text\n",
    "    Min_Salary.append(mi)\n",
    "Min_Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹11,789K',\n",
       " '₹1,636K',\n",
       " '₹2,200K',\n",
       " '₹1,024K',\n",
       " '₹2,769K',\n",
       " '₹1,597K',\n",
       " '₹1,168K',\n",
       " '₹1,719K',\n",
       " '₹1,281K',\n",
       " '₹1,835K',\n",
       " '₹1,911K',\n",
       " '₹1,227K',\n",
       " '₹1,592K',\n",
       " '₹3,283K',\n",
       " '₹2,035K',\n",
       " '₹1,377K',\n",
       " '₹1,681K',\n",
       " '₹1,807K',\n",
       " '₹1,140K',\n",
       " '₹3,561K']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping the maximum salary\n",
    "max=driver.find_elements_by_xpath(\"//div[@class='common__RangeBarStyle__values common__flex__justifySpaceBetween common__flex__container ']/span[2]\")\n",
    "\n",
    "for i in max:\n",
    "    ma=i.text\n",
    "    Max_Salary.append(ma)\n",
    "Max_Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹ 12,81,419',\n",
       " '₹ 7,52,052',\n",
       " '₹ 9,98,925',\n",
       " '₹ 6,02,000',\n",
       " '₹ 7,71,657',\n",
       " '₹ 12,22,902',\n",
       " '₹ 7,91,015',\n",
       " '₹ 12,15,138',\n",
       " '₹ 10,21,889',\n",
       " '₹ 10,00,000',\n",
       " '₹ 14,33,387',\n",
       " '₹ 11,42,351',\n",
       " '₹ 12,57,579',\n",
       " '₹ 15,53,977',\n",
       " '₹ 13,09,262',\n",
       " '₹ 5,96,779',\n",
       " '₹ 10,67,848',\n",
       " '₹ 17,00,000',\n",
       " '₹ 9,75,474',\n",
       " '₹ 35,11,792']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping the average salary\n",
    "avg=driver.find_elements_by_xpath(\"//div[@class='col-2 d-none d-md-flex flex-row justify-content-end']/strong\")\n",
    "\n",
    "for i in avg:\n",
    "    av=i.text\n",
    "    Average_Salary.append(av)\n",
    "Average_Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Delhivery',\n",
       " 'Ericsson-Worldwide',\n",
       " 'Accenture',\n",
       " 'Tata Consultancy Services',\n",
       " 'IBM',\n",
       " 'UnitedHealth Group',\n",
       " 'Valiance Solutions',\n",
       " 'Innovaccer',\n",
       " 'Cognizant Technology Solutions',\n",
       " 'ZS Associates',\n",
       " 'OYO',\n",
       " 'EXL Service',\n",
       " 'Optum',\n",
       " 'Sprinklr',\n",
       " 'dunnhumby',\n",
       " 'Algo8.ai',\n",
       " 'Tech Mahindra',\n",
       " 'Publicis Sapient',\n",
       " 'Nagarro',\n",
       " 'Times Internet']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping the company name\n",
    "name=driver.find_elements_by_xpath(\"//div[@data-test='job-info']/p[2]\")\n",
    "\n",
    "for i in name:\n",
    "    nm=i.text\n",
    "    Company_Name.append(nm)\n",
    "Company_Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Min_Salary</th>\n",
       "      <th>Max_Salary</th>\n",
       "      <th>Average_Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Delhivery</td>\n",
       "      <td>₹456K</td>\n",
       "      <td>₹11,789K</td>\n",
       "      <td>₹ 12,81,419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ericsson-Worldwide</td>\n",
       "      <td>₹420K</td>\n",
       "      <td>₹1,636K</td>\n",
       "      <td>₹ 7,52,052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>₹585K</td>\n",
       "      <td>₹2,200K</td>\n",
       "      <td>₹ 9,98,925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>₹336K</td>\n",
       "      <td>₹1,024K</td>\n",
       "      <td>₹ 6,02,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IBM</td>\n",
       "      <td>₹595K</td>\n",
       "      <td>₹2,769K</td>\n",
       "      <td>₹ 7,71,657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>₹727K</td>\n",
       "      <td>₹1,597K</td>\n",
       "      <td>₹ 12,22,902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Valiance Solutions</td>\n",
       "      <td>₹509K</td>\n",
       "      <td>₹1,168K</td>\n",
       "      <td>₹ 7,91,015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Innovaccer</td>\n",
       "      <td>₹629K</td>\n",
       "      <td>₹1,719K</td>\n",
       "      <td>₹ 12,15,138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cognizant Technology Solutions</td>\n",
       "      <td>₹804K</td>\n",
       "      <td>₹1,281K</td>\n",
       "      <td>₹ 10,21,889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ZS Associates</td>\n",
       "      <td>₹205K</td>\n",
       "      <td>₹1,835K</td>\n",
       "      <td>₹ 10,00,000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Company_Name Min_Salary Max_Salary Average_Salary\n",
       "0                       Delhivery      ₹456K   ₹11,789K    ₹ 12,81,419\n",
       "1              Ericsson-Worldwide      ₹420K    ₹1,636K     ₹ 7,52,052\n",
       "2                       Accenture      ₹585K    ₹2,200K     ₹ 9,98,925\n",
       "3       Tata Consultancy Services      ₹336K    ₹1,024K     ₹ 6,02,000\n",
       "4                             IBM      ₹595K    ₹2,769K     ₹ 7,71,657\n",
       "5              UnitedHealth Group      ₹727K    ₹1,597K    ₹ 12,22,902\n",
       "6              Valiance Solutions      ₹509K    ₹1,168K     ₹ 7,91,015\n",
       "7                      Innovaccer      ₹629K    ₹1,719K    ₹ 12,15,138\n",
       "8  Cognizant Technology Solutions      ₹804K    ₹1,281K    ₹ 10,21,889\n",
       "9                   ZS Associates      ₹205K    ₹1,835K    ₹ 10,00,000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a dataframe\n",
    "import pandas as pd\n",
    "data_scientist=pd.DataFrame({})\n",
    "data_scientist['Company_Name']=Company_Name[0:10]\n",
    "data_scientist['Min_Salary']=Min_Salary[0:10]\n",
    "data_scientist['Max_Salary']=Max_Salary[0:10]\n",
    "data_scientist['Average_Salary']=Average_Salary[0:10]\n",
    "data_scientist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6 : Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes: \n",
    "        1. Brand \n",
    "        2. Product Description \n",
    "        3. Price \n",
    "        4. Discount % \n",
    " \n",
    "To scrape the data you have to go through following steps: \n",
    "    \n",
    "1. Go to flipkart webpage by url   https://www.flipkart.com/ \n",
    "2. Enter “sunglasses” in the search field where “search for products, brands and more” is written and click the search icon \n",
    "3. after that you will reach to a webpage having a lot of sunglasses. From this page you can scrap the required data as usual. \n",
    "4. after scraping data from the first page, go to the “Next” Button at the bottom of the page , then click on it \n",
    "5. Now scrape data from this page as usual 6. repeat this until you get data for 100 sunglasses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(executable_path=\"C:\\\\Users\\\\HP\\\\Downloads\\\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.flipkart.com/search?q=sunglasses&sid=26x&as=on&as-show=on&otracker=AS_QueryStore_OrganicAutoSuggest_1_8_na_na_na&otracker1=AS_QueryStore_OrganicAutoSuggest_1_8_na_na_na&as-pos=1&as-type=RECENT&suggestionId=sunglasses%7CSunglasses&requestId=272f4cc8-5eef-4f52-a85f-1e8ac835c2a0&as-searchtext=SUNGLASS\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists for scraping data\n",
    "Brand=[]\n",
    "Product_Description=[]\n",
    "Price=[]\n",
    "Discount=[] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,4):\n",
    "    brand=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")#scraping the brand of sunglasses\n",
    "    for l in brand:\n",
    "        Brand.append(l.text)\n",
    "        \n",
    "    product=driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\") #scraping the product description   \n",
    "    for j in product:\n",
    "        Product_Description.append(j.text)\n",
    "        \n",
    "    price=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")    #scraping the price of sunglasses\n",
    "    for k in price:\n",
    "        Price.append(k.text)  \n",
    "        \n",
    "    dis=driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']/span\")   #scraping the discount% \n",
    "    for p in dis:\n",
    "        Discount.append(p.text) \n",
    "        \n",
    "    next=driver.find_elements_by_xpath(\"//nav[@class='yFHi8N']/a\") #scraping the path of next button\n",
    "    driver.get(next[i].get_attribute('href'))#scraping the url for next button for each page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ROZZETTA CRAFT',\n",
       " 'Rozdeal',\n",
       " 'FDA COLLECTION',\n",
       " 'shah collections',\n",
       " 'Phenomenal',\n",
       " 'shah collections',\n",
       " 'Trendy Glasses',\n",
       " 'like future',\n",
       " 'Fastrack',\n",
       " 'povty']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Brand[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mirrored, UV Protection Round Sunglasses (Free Size)',\n",
       " 'Polarized, Night Vision, Riding Glasses, Mirrored, UV P...',\n",
       " 'UV Protection, Polarized, Mirrored Rectangular Sunglass...',\n",
       " 'UV Protection, Mirrored Retro Square Sunglasses (53)',\n",
       " 'UV Protection Round Sunglasses (Free Size)',\n",
       " 'UV Protection Retro Square Sunglasses (Free Size)',\n",
       " 'Mirrored Aviator Sunglasses (Free Size)',\n",
       " 'Gradient, UV Protection Wayfarer Sunglasses (Free Size)',\n",
       " 'UV Protection Wayfarer Sunglasses (Free Size)',\n",
       " 'UV Protection Retro Square Sunglasses (Free Size)']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Product_Description[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹399',\n",
       " '₹749',\n",
       " '₹220',\n",
       " '₹219',\n",
       " '₹399',\n",
       " '₹349',\n",
       " '₹309',\n",
       " '₹181',\n",
       " '₹699',\n",
       " '₹245']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Price[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['72% off',\n",
       " '81% off',\n",
       " '83% off',\n",
       " '78% off',\n",
       " '80% off',\n",
       " '79% off',\n",
       " '75% off',\n",
       " '83% off',\n",
       " '12% off',\n",
       " '75% off']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Discount[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160 107 160 160\n"
     ]
    }
   ],
   "source": [
    "print(len(Brand),len(Product_Description),len(Price),len(Discount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product_Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>Mirrored, UV Protection Round Sunglasses (Free...</td>\n",
       "      <td>₹399</td>\n",
       "      <td>72% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rozdeal</td>\n",
       "      <td>Polarized, Night Vision, Riding Glasses, Mirro...</td>\n",
       "      <td>₹749</td>\n",
       "      <td>81% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FDA COLLECTION</td>\n",
       "      <td>UV Protection, Polarized, Mirrored Rectangular...</td>\n",
       "      <td>₹220</td>\n",
       "      <td>83% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shah collections</td>\n",
       "      <td>UV Protection, Mirrored Retro Square Sunglasse...</td>\n",
       "      <td>₹219</td>\n",
       "      <td>78% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Phenomenal</td>\n",
       "      <td>UV Protection Round Sunglasses (Free Size)</td>\n",
       "      <td>₹399</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>I Flash</td>\n",
       "      <td>UV Protection Round Sunglasses (54)</td>\n",
       "      <td>₹174</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Silver Kartz</td>\n",
       "      <td>UV Protection Oval Sunglasses (56)</td>\n",
       "      <td>₹233</td>\n",
       "      <td>84% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Aviator Sunglasses (Free Size)</td>\n",
       "      <td>₹659</td>\n",
       "      <td>17% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection, Riding Glasses, Mirrored Rectan...</td>\n",
       "      <td>₹759</td>\n",
       "      <td>15% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection, Mirrored Clubmaster Sunglasses ...</td>\n",
       "      <td>₹380</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Brand                                Product_Description Price  \\\n",
       "0     ROZZETTA CRAFT  Mirrored, UV Protection Round Sunglasses (Free...  ₹399   \n",
       "1            Rozdeal  Polarized, Night Vision, Riding Glasses, Mirro...  ₹749   \n",
       "2     FDA COLLECTION  UV Protection, Polarized, Mirrored Rectangular...  ₹220   \n",
       "3   shah collections  UV Protection, Mirrored Retro Square Sunglasse...  ₹219   \n",
       "4         Phenomenal         UV Protection Round Sunglasses (Free Size)  ₹399   \n",
       "..               ...                                                ...   ...   \n",
       "95           I Flash                UV Protection Round Sunglasses (54)  ₹174   \n",
       "96      Silver Kartz                 UV Protection Oval Sunglasses (56)  ₹233   \n",
       "97          Fastrack       UV Protection Aviator Sunglasses (Free Size)  ₹659   \n",
       "98          Fastrack  UV Protection, Riding Glasses, Mirrored Rectan...  ₹759   \n",
       "99    ROZZETTA CRAFT  UV Protection, Mirrored Clubmaster Sunglasses ...  ₹380   \n",
       "\n",
       "   Discount  \n",
       "0   72% off  \n",
       "1   81% off  \n",
       "2   83% off  \n",
       "3   78% off  \n",
       "4   80% off  \n",
       "..      ...  \n",
       "95  85% off  \n",
       "96  84% off  \n",
       "97  17% off  \n",
       "98  15% off  \n",
       "99  77% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a dataframe\n",
    "import pandas as pd\n",
    "Sunglasses=pd.DataFrame({})\n",
    "Sunglasses['Brand']=Brand[0:100]\n",
    "Sunglasses['Product_Description']=Product_Description[0:100]\n",
    "Sunglasses['Price']=Price[0:100]\n",
    "Sunglasses['Discount']=Discount[0:100]\n",
    "Sunglasses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: https://www.flipkart.com/apple-iphone-11-black-64-gb-includesearpods-poweradapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKC TSVZAXUHGREPBFGI&marketplace. \n",
    " \n",
    "You have to scrape the following attributes. These are  \n",
    "1. Rating   \n",
    "2. Review_summary     \n",
    "3. Full review \n",
    "You have to scrape this data for first 100 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(executable_path=\"C:\\\\Users\\\\HP\\\\Downloads\\\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGR3QP11A&marketplace=FLIPKART\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists for scraping data\n",
    "Rating=[]   \n",
    "Review_summary=[]     \n",
    "Full_review=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,11):\n",
    "    rat=driver.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq']\") #scraping the ratings\n",
    "    for l in rat:\n",
    "        Rating.append(l.text)\n",
    "        \n",
    "    sum=driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\")    #scraping the review summary\n",
    "    for j in sum:\n",
    "        Review_summary.append(j.text)  \n",
    "        \n",
    "    rev=driver.find_elements_by_xpath(\"//div[@class='row']\")    #scraping the full review\n",
    "    for k in rev:\n",
    "        Full_review.append(k.text)\n",
    "    \n",
    "    next=driver.find_elements_by_xpath(\"//nav[@class='yFHi8N']/a\")#scraping the path of next button\n",
    "    driver.get(next[i].get_attribute('href'))    #scraping the url for next button for each page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109 110 462\n"
     ]
    }
   ],
   "source": [
    "print(len(Rating),len(Review_summary),len(Full_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review_summary</th>\n",
       "      <th>Full_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>4.7★</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>5\\nPerfect product!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>Flipkart Customer\\nCertified Buyer, Hyderabad\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>2068344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Delightful</td>\n",
       "      <td>Avishek Naha\\nCertified Buyer, Serampore\\nOct,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>10041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Super!</td>\n",
       "      <td>5\\nBrilliant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>I have migrated from OP 7pro... and trust me, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Super!</td>\n",
       "      <td>Pratik M\\nCertified Buyer, New Delhi\\n7 months...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating      Review_summary  \\\n",
       "0       5    Perfect product!   \n",
       "1       5       Great product   \n",
       "2       5    Perfect product!   \n",
       "3       5  Highly recommended   \n",
       "4       5    Perfect product!   \n",
       "..    ...                 ...   \n",
       "95      5          Delightful   \n",
       "96      5      Simply awesome   \n",
       "97      5              Super!   \n",
       "98      5       Great product   \n",
       "99      5              Super!   \n",
       "\n",
       "                                          Full_review  \n",
       "0                                                4.7★  \n",
       "1                                 5\\nPerfect product!  \n",
       "2   Amazing phone with great cameras and better ba...  \n",
       "3   Flipkart Customer\\nCertified Buyer, Hyderabad\\...  \n",
       "4                                             2068344  \n",
       "..                                                ...  \n",
       "95  Avishek Naha\\nCertified Buyer, Serampore\\nOct,...  \n",
       "96                                              10041  \n",
       "97                                       5\\nBrilliant  \n",
       "98  I have migrated from OP 7pro... and trust me, ...  \n",
       "99  Pratik M\\nCertified Buyer, New Delhi\\n7 months...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a dataframe\n",
    "import pandas as pd\n",
    "Iphone=pd.DataFrame({})\n",
    "Iphone['Rating']=Rating[0:100]\n",
    "Iphone['Review_summary']=Review_summary[0:100]\n",
    "Iphone['Full_review']=Full_review[0:100]\n",
    "Iphone\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field. You have to scrape 4 attributes of each sneaker : \n",
    "        \n",
    "1. Brand \n",
    "2. Product Description \n",
    "3. Price \n",
    "4. discount % "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(executable_path=\"C:\\\\Users\\\\HP\\\\Downloads\\\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.flipkart.com/search?q=sneakers&as=on&as-show=on&otracker=AS_Query_OrganicAutoSuggest_3_8_na_na_na&otracker1=AS_Query_OrganicAutoSuggest_3_8_na_na_na&as-pos=3&as-type=RECENT&suggestionId=sneakers&requestId=32b3211d-a7ac-4369-b960-d9dbff80cc97&as-searchtext=sneakers\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists for scraping data\n",
    "Brand=[]\n",
    "Product_Description=[]\n",
    "Price=[]\n",
    "Discount=[] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,4):\n",
    "    brand=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")#scraping the brand of sneakers\n",
    "    for l in brand:\n",
    "        Brand.append(l.text)\n",
    "        \n",
    "    product=driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")    #scraping the product description\n",
    "    for j in product:\n",
    "        Product_Description.append(j.text)\n",
    "        \n",
    "    price=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")    #scraping the price of each sneakers\n",
    "    for k in price:\n",
    "        Price.append(k.text)  \n",
    "        \n",
    "    dis=driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']/span\")    #scraping the discount %\n",
    "    for p in dis:\n",
    "        Discount.append(p.text) \n",
    "        \n",
    "    next=driver.find_elements_by_xpath(\"//nav[@class='yFHi8N']/a\")#scraping the path of next button\n",
    "    driver.get(next[i].get_attribute('href'))#scraping the url for next button for each page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160 132 160 160\n"
     ]
    }
   ],
   "source": [
    "print(len(Brand),len(Product_Description),len(Price),len(Discount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product_Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>French Connection</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹2,058</td>\n",
       "      <td>48% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Marc Ecko</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹1,049</td>\n",
       "      <td>52% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Combo Pack of 4 Casual Sneakers With Sneakers ...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>75% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>World Wear Footwear</td>\n",
       "      <td>Combo Pack of 4 Latest Collection Stylish Casu...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>75% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>171 Smart Tan Lace-Ups Casuals for Men Sneaker...</td>\n",
       "      <td>₹399</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Clymb</td>\n",
       "      <td>Casual Sneakers Shoes For Men Sneakers For Men</td>\n",
       "      <td>₹299</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>STRANGER BROTHERS</td>\n",
       "      <td>Casual , Partywear Sneakers Shoes For Men's An...</td>\n",
       "      <td>₹549</td>\n",
       "      <td>45% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>PERY-PAO</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹437</td>\n",
       "      <td>56% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Wika</td>\n",
       "      <td>Combo Pack Of 3 Sneakers For Men</td>\n",
       "      <td>₹395</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Layasa</td>\n",
       "      <td>Stylish and Comfortable Sneakers For Men</td>\n",
       "      <td>₹379</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Brand                                Product_Description  \\\n",
       "0     French Connection                                   Sneakers For Men   \n",
       "1             Marc Ecko                                   Sneakers For Men   \n",
       "2                Chevit  Combo Pack of 4 Casual Sneakers With Sneakers ...   \n",
       "3   World Wear Footwear  Combo Pack of 4 Latest Collection Stylish Casu...   \n",
       "4          Robbie jones  171 Smart Tan Lace-Ups Casuals for Men Sneaker...   \n",
       "..                  ...                                                ...   \n",
       "95                Clymb     Casual Sneakers Shoes For Men Sneakers For Men   \n",
       "96    STRANGER BROTHERS  Casual , Partywear Sneakers Shoes For Men's An...   \n",
       "97             PERY-PAO                                   Sneakers For Men   \n",
       "98                 Wika                   Combo Pack Of 3 Sneakers For Men   \n",
       "99               Layasa           Stylish and Comfortable Sneakers For Men   \n",
       "\n",
       "     Price Discount  \n",
       "0   ₹2,058  48% off  \n",
       "1   ₹1,049  52% off  \n",
       "2     ₹499  75% off  \n",
       "3     ₹499  75% off  \n",
       "4     ₹399  60% off  \n",
       "..     ...      ...  \n",
       "95    ₹299  70% off  \n",
       "96    ₹549  45% off  \n",
       "97    ₹437  56% off  \n",
       "98    ₹395  60% off  \n",
       "99    ₹379  62% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a dataframe\n",
    "import pandas as pd\n",
    "Sneakers=pd.DataFrame({})\n",
    "Sneakers['Brand']=Brand[0:100]\n",
    "Sneakers['Product_Description']=Product_Description[0:100]\n",
    "Sneakers['Price']=Price[0:100]\n",
    "Sneakers['Discount']=Discount[0:100]\n",
    "Sneakers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q9: Go to the link - https://www.myntra.com/shoes  Set Price filter to “Rs. 6649 to Rs. 13099” , Color filter to “Black” \n",
    "\n",
    "  \n",
    "And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe description, price of the shoe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(executable_path=\"C:\\\\Users\\\\HP\\\\Downloads\\\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.myntra.com/shoes?f=Color%3ABlack_36454f&plaEnabled=false&rf=Price%3A5839.0_11559.0_5839.0%20TO%2011559.0\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists for scraping data\n",
    "Shoe_Brand=[]\n",
    "Shoe_Description=[]\n",
    "Price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_page=0\n",
    "end_page=3\n",
    "for page in range(start_page,end_page+1): \n",
    "    nxt_button=driver.find_element_by_xpath(\"//li[@class='pagination-next']\")#scraping the path of next button\n",
    "\n",
    "    brand=driver.find_elements_by_xpath(\"//h3[@class='product-brand']\")#scraping the brand\n",
    "    for l in brand:\n",
    "        Shoe_Brand.append(l.text)\n",
    "        \n",
    "    product=driver.find_elements_by_xpath(\"//h4[@class='product-product']\")    #scraping the product description\n",
    "    for j in product:\n",
    "        Shoe_Description.append(j.text)\n",
    "        \n",
    "    price=driver.find_elements_by_xpath(\"//span[@class='product-discountedPrice']\")    #scraping the discounted price\n",
    "    for k in price:\n",
    "        Price.append(k.text)  \n",
    "        \n",
    "    if nxt_button.text=='next':\n",
    "            nxt_button.click()\n",
    "            time.sleep(5)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 200 144\n"
     ]
    }
   ],
   "source": [
    "print(len(Shoe_Brand),len(Shoe_Description),len(Price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Shoe_Brand</th>\n",
       "      <th>Shoe_Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men React Infinity Running</td>\n",
       "      <td>Rs. 11099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men Zoom Running Shoes</td>\n",
       "      <td>Rs. 6399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men Solid SKYVE MAX Sneakers</td>\n",
       "      <td>Rs. 6599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kenneth Cole</td>\n",
       "      <td>Men Solid Formal Genuine Leather Derbys</td>\n",
       "      <td>Rs. 6153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Women Slip-On Sneakers</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Kenneth Cole</td>\n",
       "      <td>Men Solid Leather Formal Brogues</td>\n",
       "      <td>Rs. 6499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>HOVR Sonic 3 Running Shoes</td>\n",
       "      <td>Rs. 8999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Men Leather Sneakers</td>\n",
       "      <td>Rs. 8999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Kenneth Cole</td>\n",
       "      <td>Men Leather Formal Derbys</td>\n",
       "      <td>Rs. 8999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Kenneth Cole</td>\n",
       "      <td>Men Solid Leather Formal Derbys</td>\n",
       "      <td>Rs. 9349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Shoe_Brand                         Shoe_Description      Price\n",
       "0           Nike               Men React Infinity Running  Rs. 11099\n",
       "1           Nike                   Men Zoom Running Shoes   Rs. 6399\n",
       "2           Nike             Men Solid SKYVE MAX Sneakers   Rs. 6599\n",
       "3   Kenneth Cole  Men Solid Formal Genuine Leather Derbys   Rs. 6153\n",
       "4           Geox                   Women Slip-On Sneakers   Rs. 7999\n",
       "..           ...                                      ...        ...\n",
       "95  Kenneth Cole         Men Solid Leather Formal Brogues   Rs. 6499\n",
       "96  UNDER ARMOUR               HOVR Sonic 3 Running Shoes   Rs. 8999\n",
       "97          Geox                     Men Leather Sneakers   Rs. 8999\n",
       "98  Kenneth Cole                Men Leather Formal Derbys   Rs. 8999\n",
       "99  Kenneth Cole          Men Solid Leather Formal Derbys   Rs. 9349\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a dataframe\n",
    "import pandas as pd\n",
    "Shoes=pd.DataFrame({})\n",
    "Shoes['Shoe_Brand']=Shoe_Brand[0:100]\n",
    "Shoes['Shoe_Description']=Shoe_Description[0:100]\n",
    "Shoes['Price']=Price[0:100]\n",
    "Shoes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q10:  Go to webpage https://www.amazon.in/    Enter “Laptop” in the search field and then click the search icon.   Then set CPU Type filter to “Intel Core i7” and “Intel Core i9”  \n",
    "WEB SCRAPING ASSIGNMENT-2 \n",
    ". \n",
    " \n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop: \n",
    "    \n",
    "1. title \n",
    "2. Ratings \n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(executable_path=\"C:\\\\Users\\\\HP\\\\Downloads\\\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.amazon.in/s?k=laptop&i=computers&rh=n%3A1375424031%2Cp_n_feature_thirteen_browse-bin%3A12598163031%7C16757432031&dc&qid=1611567255&rnid=12598141031&ref=sr_nr_p_n_feature_thirteen_browse-bin_17\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists for scraping data\n",
    "Title=[] \n",
    "Ratings=[] \n",
    "Price=[] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dell Inspiron 5501 15.6 Inch FHD Laptop (10th Gen i7-1065G7/8 GB/512 SSD/2 GB Nvidia Graphics/Win 10 + MS Office H&S 2019/Silver) D560213WIN9S',\n",
       " 'Dell XPS 9570 15.6-inch FHD Laptop (8th Gen Core i7-8750H/16GB/512 GB SSD/Windows 10 + MS Office/ Nvidia GTX 1050Ti 4GB Graphics/Silver)',\n",
       " 'Mi Notebook Horizon Edition 14 Intel Core i5-10210U 10th Gen Thin and Light Laptop(8GB/512GB SSD/Windows 10/Nvidia MX350 2GB Graphics/Grey/1.35Kg), XMA1904-AR+Webcam',\n",
       " '(Renewed) Dell Latitude E7470 14-inch Laptop (Core i7 6th Gen/16GB/1 TB HDD/Windows 10/MS Office Pro 2019/Intel Graphics), Black',\n",
       " 'Lenovo Yoga S740 Intel Core i7 10th Gen 14 inch UHD Ultra Thin and Light Laptop (16GB/1TB SSD/Windows/Office/NVIDIA MX250 2GB/Iron Grey/1.4Kg), 81RS00B0IN',\n",
       " '(Renewed) Dell Latitude E7470 14-inch Laptop (Core i7 6th Gen/8GB(Up to 16)/1 TB HDD/Windows 10/MS Office Pro 2019/Intel Graphics), Black',\n",
       " '(Renewed) Dell Latitude E7470 14-inch Laptop (Core i7 6th Gen/8GB(Up to 16)/500 GB HDD/Windows 10/MS Office Pro 2019/Intel Graphics), Black',\n",
       " '(Renewed) Dell Latitude E7470 14-inch Laptop (Core i7 6th Gen/16GB/500 GB HDD/Windows 10/MS Office Pro 2019/Intel Graphics), Black',\n",
       " 'MSI GF63 Thin Core i7 9th Gen - (8 GB/512 GB SSD/Windows 10 Home/4 GB Graphics/NVIDIA Geforce GTX 1650 Ti with Max-Q) GF63 Thin 9SCSR-1039IN Gaming Laptop (15.6 inch, Black, 1.86 kg)',\n",
       " '(Renewed) Dell Latitude E5570 15-inch Laptop (Core I7 6th Gen/8 GB/256 GB SSD/Windows 10/MS Office Pro 2019/AMD Graphics), Black']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping the name/title \n",
    "title=driver.find_elements_by_xpath(\"//span[@class='a-size-medium a-color-base a-text-normal']\")\n",
    "for l in title:\n",
    "     Title.append(l.text)\n",
    "\n",
    "Title[0:10]      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['85,890',\n",
       " '1,27,990',\n",
       " '54,899',\n",
       " '55,299',\n",
       " '96,551',\n",
       " '53,599',\n",
       " '52,699',\n",
       " '54,399',\n",
       " '70,990',\n",
       " '61,999']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping the price of laptop\n",
    "price=driver.find_elements_by_xpath(\"//span[@class='a-price-whole']\")    \n",
    "for k in price:\n",
    "    Price.append(k.text)\n",
    "    \n",
    "Price[0:10]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.common.exceptions import  NoSuchElementException\n",
    "urls=[]\n",
    "for i in driver.find_elements_by_xpath(\"//a[@class='a-link-normal a-text-normal']\"):#scraping the path of url for each laptop\n",
    "    urls.append(i.get_attribute(\"href\")) \n",
    "\n",
    "for url in urls[0:10]:\n",
    "    \n",
    "    try:\n",
    "        driver.get(url)\n",
    "        rat=driver.find_element_by_xpath(\"//span[@class='a-size-medium a-color-base']\").text #scraping the ratings of each laptop\n",
    "        Ratings.append(rat)\n",
    "    except NoSuchElementException :\n",
    "        Ratings.append(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 10 28\n"
     ]
    }
   ],
   "source": [
    "print(len(Title),len(Ratings),len(Price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dell Inspiron 5501 15.6 Inch FHD Laptop (10th ...</td>\n",
       "      <td>3.4 out of 5</td>\n",
       "      <td>85,890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dell XPS 9570 15.6-inch FHD Laptop (8th Gen Co...</td>\n",
       "      <td>2.5 out of 5</td>\n",
       "      <td>1,27,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i5-1...</td>\n",
       "      <td>4.2 out of 5</td>\n",
       "      <td>54,899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Renewed) Dell Latitude E7470 14-inch Laptop (...</td>\n",
       "      <td>---</td>\n",
       "      <td>55,299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lenovo Yoga S740 Intel Core i7 10th Gen 14 inc...</td>\n",
       "      <td>3.3 out of 5</td>\n",
       "      <td>96,551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(Renewed) Dell Latitude E7470 14-inch Laptop (...</td>\n",
       "      <td>---</td>\n",
       "      <td>53,599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(Renewed) Dell Latitude E7470 14-inch Laptop (...</td>\n",
       "      <td>---</td>\n",
       "      <td>52,699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(Renewed) Dell Latitude E7470 14-inch Laptop (...</td>\n",
       "      <td>---</td>\n",
       "      <td>54,399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MSI GF63 Thin Core i7 9th Gen - (8 GB/512 GB S...</td>\n",
       "      <td>---</td>\n",
       "      <td>70,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(Renewed) Dell Latitude E5570 15-inch Laptop (...</td>\n",
       "      <td>---</td>\n",
       "      <td>61,999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title       Ratings     Price\n",
       "0  Dell Inspiron 5501 15.6 Inch FHD Laptop (10th ...  3.4 out of 5    85,890\n",
       "1  Dell XPS 9570 15.6-inch FHD Laptop (8th Gen Co...  2.5 out of 5  1,27,990\n",
       "2  Mi Notebook Horizon Edition 14 Intel Core i5-1...  4.2 out of 5    54,899\n",
       "3  (Renewed) Dell Latitude E7470 14-inch Laptop (...           ---    55,299\n",
       "4  Lenovo Yoga S740 Intel Core i7 10th Gen 14 inc...  3.3 out of 5    96,551\n",
       "5  (Renewed) Dell Latitude E7470 14-inch Laptop (...           ---    53,599\n",
       "6  (Renewed) Dell Latitude E7470 14-inch Laptop (...           ---    52,699\n",
       "7  (Renewed) Dell Latitude E7470 14-inch Laptop (...           ---    54,399\n",
       "8  MSI GF63 Thin Core i7 9th Gen - (8 GB/512 GB S...           ---    70,990\n",
       "9  (Renewed) Dell Latitude E5570 15-inch Laptop (...           ---    61,999"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a dataframe\n",
    "import pandas as pd\n",
    "Laptop=pd.DataFrame({})\n",
    "Laptop['Title']=Title[0:10]\n",
    "Laptop['Ratings']=Ratings[0:10]\n",
    "Laptop['Price']=Price[0:10]\n",
    "Laptop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
